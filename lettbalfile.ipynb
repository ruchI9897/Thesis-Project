{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lettbalfile.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOPjWrL2bsZ5WsQizrfMgw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruchI9897/Thesis-Project/blob/master/lettbalfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w8BDlOKwief",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "# Scikit-learn library: For SVM\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdZYjLnjzaa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/letter-recognition.csv') # Reading the file .csv\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE6f7Ct4zyiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x = df.iloc[: , 1:17].values\n",
        "y = df.iloc[:, 0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADfAWUvw1U99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbBzvm5o1Xom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x = StandardScaler()\n",
        "xtrain = sc_x.fit_transform(xtrain)\n",
        "xtest = sc_x.transform(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTcNByCBNi9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b4a2a532-bd0b-4088-8a23-a4f303ae8b8b"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# an initial SVM model with linear kernel   \n",
        "svm_linear = svm.SVC(kernel='rbf')\n",
        "\n",
        "# fit\n",
        "svm_linear.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql_HSBBTN2OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = svm_linear.predict(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBDMiX6UOlLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5805c3b-3cd5-481c-d64a-932937fd1986"
      },
      "source": [
        "metrics.accuracy_score(y_true=ytest, y_pred=predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWqBGUNA-qoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def split(filehandler, delimiter=',', row_limit=4000,\n",
        "          output_name_template='output_%s.csv', output_path='.', keep_headers=True):\n",
        "    import csv\n",
        "    reader = csv.reader(filehandler, delimiter=delimiter)\n",
        "    current_piece = 1\n",
        "    current_out_path = os.path.join(\n",
        "        output_path,\n",
        "        output_name_template % current_piece\n",
        "    )\n",
        "    current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
        "    current_limit = row_limit\n",
        "    if keep_headers:\n",
        "        headers = next(reader)\n",
        "        current_out_writer.writerow(headers)\n",
        "    for i, row in enumerate(reader):\n",
        "        if i + 1 > current_limit:\n",
        "            current_piece += 1\n",
        "            current_limit = row_limit * current_piece\n",
        "            current_out_path = os.path.join(\n",
        "                output_path,\n",
        "                output_name_template % current_piece\n",
        "            )\n",
        "            current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
        "            if keep_headers:\n",
        "                current_out_writer.writerow(headers)\n",
        "        current_out_writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vLVsu3M-yeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split(open('/content/letter-recognition.csv', 'r'));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o9_QNOy7Yl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "564e5029-bf06-4b88-92c0-592bc03d8024"
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def clustering(input_file, k_size):\n",
        "    df = pd.read_csv(input_file)\n",
        "    df['letter'] = df['letter'].astype('category').cat.codes\n",
        "    # x = df.ix[:,[0,1,2,3,4,5,6]]\n",
        "    x = df.iloc[:,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
        "    y = df.iloc[:,0]\n",
        "\n",
        "    print(x.head())\n",
        "    k=k_size\n",
        "\n",
        "    model = KMeans(n_clusters=k)\n",
        "    model.fit(x)\n",
        "\n",
        "    centroids = model.cluster_centers_\n",
        "    labels = model.labels_\n",
        "\n",
        "    # INSERT THE LABEL OF CLUSTER TO DATAFRAME\n",
        "    label_col = pd.Series(labels)\n",
        "    x[\"class\"] = y\n",
        "    x[\"cluster\"] = label_col.values\n",
        "\n",
        "    # SAVE THE DATA TO ITS OWN CSV BASED ON ITS CLUSTER\n",
        "    clusterNames = list(range(0,k))\n",
        "\n",
        "    dir_name = \"%sclusters %s\"%(k,time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "    os.makedirs(\"output/training_clustered/%s\"%dir_name, exist_ok=True)\n",
        "\n",
        "    # store the centroids\n",
        "    df_centroids = pd.DataFrame(centroids,columns=['attr1', 'attr2', 'attr3', 'attr4', 'attr5', 'attr6', 'attr7','attr8', 'attr9', 'attr10', 'attr11', 'attr12', 'attr13', 'attr14', 'attr15','attr16'])\n",
        "    # df_centroids = pd.DataFrame(centroids,columns=['attr1', 'attr2', 'attr3', 'attr4' 'attr5', 'attr6', 'attr7'])\n",
        "    df_centroids.to_csv(\"output/training_clustered/%s/centroids.csv\"%dir_name, index=False)\n",
        "\n",
        "    print(df_centroids.head())\n",
        "\n",
        "    for name in clusterNames:\n",
        "        temp = x.loc[x['cluster']==name]\n",
        "        temp.to_csv(\"output/training_clustered/%s/%s.csv\"%(dir_name,name), index=False)\n",
        "        # classCount = temp['class'].value_counts(sort=False)\n",
        "        class_count = np.bincount(temp['class'])\n",
        "        ii = np.nonzero(class_count)[0]\n",
        "\n",
        "        cc = np.vstack((ii,class_count[ii])).T\n",
        "\n",
        "        print(\"Cluster-%s\"%name)\n",
        "        # print(class_count)\n",
        "        print(cc)\n",
        "        print(\"total:\",class_count.sum())\n",
        "\n",
        "    print(\"The result files are in the %s\"%(dir_name))\n",
        "    return \"output/training_clustered/%s\"%dir_name\n",
        "\n",
        "\n",
        "k_size = 5\n",
        "\n",
        "input_file=\"/content/subset5.csv\"\n",
        "print(clustering(input_file, k_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   xbox   ybox   width   height  onpix   ...  xy2bar  xedge   xedgey  yedge   yedgex\n",
            "0      4     10       6       7       9  ...       7       9       8       5       6\n",
            "1      6      9       8       4       3  ...       8       6       8       0       8\n",
            "2      6      9       8       8      10  ...       8       7       9       7      10\n",
            "3      5      6       6       4       3  ...       9       0       9       4       8\n",
            "4      5      9       7       6       4  ...       6       5       8       1       7\n",
            "\n",
            "[5 rows x 16 columns]\n",
            "      attr1     attr2     attr3  ...    attr14    attr15    attr16\n",
            "0  4.127407  8.386667  5.441481  ...  7.321481  3.626667  8.349630\n",
            "1  4.545038  7.888550  5.622901  ...  9.859542  2.076336  6.668702\n",
            "2  5.967555  9.749710  7.326767  ...  8.375435  5.776362  7.470452\n",
            "3  3.802521  7.295168  4.715336  ...  8.036765  4.099790  8.471639\n",
            "4  1.888889  2.409357  2.797661  ...  8.181287  2.604678  7.915789\n",
            "\n",
            "[5 rows x 16 columns]\n",
            "Cluster-0\n",
            "[[  0 102]\n",
            " [  1  22]\n",
            " [  3  35]\n",
            " [  4  26]\n",
            " [  5   8]\n",
            " [  6   4]\n",
            " [  7  17]\n",
            " [  8  59]\n",
            " [  9  90]\n",
            " [ 10  23]\n",
            " [ 11  55]\n",
            " [ 12  11]\n",
            " [ 13  15]\n",
            " [ 14  10]\n",
            " [ 15  16]\n",
            " [ 16  19]\n",
            " [ 17  19]\n",
            " [ 18  31]\n",
            " [ 19   3]\n",
            " [ 23  36]\n",
            " [ 25  72]]\n",
            "total: 673\n",
            "Cluster-1\n",
            "[[ 0  1]\n",
            " [ 1  1]\n",
            " [ 2 13]\n",
            " [ 4  7]\n",
            " [ 5 90]\n",
            " [ 6  1]\n",
            " [ 7  9]\n",
            " [ 8  7]\n",
            " [10  8]\n",
            " [12  4]\n",
            " [13 17]\n",
            " [15 70]\n",
            " [16  1]\n",
            " [18 10]\n",
            " [19 98]\n",
            " [20 36]\n",
            " [21 99]\n",
            " [22 70]\n",
            " [23 11]\n",
            " [24 93]\n",
            " [25  9]]\n",
            "total: 655\n",
            "Cluster-2\n",
            "[[ 0 18]\n",
            " [ 1 37]\n",
            " [ 2 24]\n",
            " [ 3 36]\n",
            " [ 4 31]\n",
            " [ 5 20]\n",
            " [ 6 41]\n",
            " [ 7 47]\n",
            " [ 8 10]\n",
            " [ 9 12]\n",
            " [10 49]\n",
            " [11 21]\n",
            " [12 64]\n",
            " [13 49]\n",
            " [14 30]\n",
            " [15 48]\n",
            " [16 35]\n",
            " [17 39]\n",
            " [18 42]\n",
            " [19 18]\n",
            " [20 35]\n",
            " [21 17]\n",
            " [22 40]\n",
            " [23 41]\n",
            " [24 31]\n",
            " [25 28]]\n",
            "total: 863\n",
            "Cluster-3\n",
            "[[ 0  5]\n",
            " [ 1 40]\n",
            " [ 2 78]\n",
            " [ 3 45]\n",
            " [ 4 55]\n",
            " [ 5  4]\n",
            " [ 6 85]\n",
            " [ 7 49]\n",
            " [ 8 13]\n",
            " [ 9 12]\n",
            " [10 43]\n",
            " [11 42]\n",
            " [12 39]\n",
            " [13 52]\n",
            " [14 72]\n",
            " [15 11]\n",
            " [16 82]\n",
            " [17 58]\n",
            " [18 50]\n",
            " [19  6]\n",
            " [20 61]\n",
            " [21  2]\n",
            " [22  3]\n",
            " [23 35]\n",
            " [24  2]\n",
            " [25 10]]\n",
            "total: 954\n",
            "Cluster-4\n",
            "[[ 0 30]\n",
            " [ 1 36]\n",
            " [ 2 27]\n",
            " [ 3 51]\n",
            " [ 4 33]\n",
            " [ 5 31]\n",
            " [ 6 33]\n",
            " [ 7 29]\n",
            " [ 8 76]\n",
            " [ 9 34]\n",
            " [10 23]\n",
            " [11 39]\n",
            " [12 26]\n",
            " [13 33]\n",
            " [14 27]\n",
            " [15 23]\n",
            " [16 31]\n",
            " [17 45]\n",
            " [18 28]\n",
            " [19 26]\n",
            " [20 36]\n",
            " [21 18]\n",
            " [22 26]\n",
            " [23 36]\n",
            " [24 19]\n",
            " [25 39]]\n",
            "total: 855\n",
            "The result files are in the 5clusters 2020-04-14 13:27:19\n",
            "output/training_clustered/5clusters 2020-04-14 13:27:19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgS07FCM-lof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "with open('ran5.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPm1FIPM_q_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def split(filehandler, delimiter=',', row_limit=171,\n",
        "          output_name_template='outputclus_%s.csv', output_path='.', keep_headers=True):\n",
        "    import csv\n",
        "    reader = csv.reader(filehandler, delimiter=delimiter)\n",
        "    current_piece = 1\n",
        "    current_out_path = os.path.join(\n",
        "        output_path,\n",
        "        output_name_template % current_piece\n",
        "    )\n",
        "    current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
        "    current_limit = row_limit\n",
        "    if keep_headers:\n",
        "        headers = next(reader)\n",
        "        current_out_writer.writerow(headers)\n",
        "    for i, row in enumerate(reader):\n",
        "        if i + 1 > current_limit:\n",
        "            current_piece += 1\n",
        "            current_limit = row_limit * current_piece\n",
        "            current_out_path = os.path.join(\n",
        "                output_path,\n",
        "                output_name_template % current_piece\n",
        "            )\n",
        "            current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n",
        "            if keep_headers:\n",
        "                current_out_writer.writerow(headers)\n",
        "        current_out_writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZ0kwIG_1TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split(open('/content/output/training_clustered/5clusters 2020-04-14 13:27:19/4.csv', 'r'));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwS2kiNnulpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "reader = csv.reader(open(\"/content/outputclus_5.csv\"))\n",
        "reader1 = csv.reader(open(\"/content/set5.csv\"))\n",
        "f = open(\"final5.csv\", \"w\")\n",
        "writer = csv.writer(f)\n",
        "\n",
        "for row in reader:\n",
        "    writer.writerow(row)\n",
        "for row in reader1:\n",
        "    writer.writerow(row)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgPjSauNxnSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "reader = csv.reader(open(\"/content/final5.csv\"))\n",
        "f = open(\"/content/set5.csv\", \"w\")\n",
        "writer = csv.writer(f)\n",
        "\n",
        "for row in reader:\n",
        "    writer.writerow(row)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKaq0vY-7CDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "with open(\"/content/letter-recognition.csv\") as fr:\n",
        "    with open(\"ran1.csv\", \"w\") as f1, open(\"ran2.csv\", \"w\") as f2, open(\"ran3.csv\", \"w\") as f3,open(\"ran4.csv\", \"w\") as f4, open(\"ran5.csv\", \"w\") as f5:\n",
        "        for line in fr:\n",
        "            f = random.choice([f1, f2, f3,f4,f5])\n",
        "            f.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}